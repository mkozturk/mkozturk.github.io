[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Combining forecasts for better estimates\n\n\n\n\n\n\n\ndata science\n\n\ntime series forecast\n\n\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\nKaan Öztürk\n\n\n\n\n\n\n  \n\n\n\n\nSeçim Sandığında Bayes\n\n\n\n\n\n\n\nBayesian analysis\n\n\napplied probability\n\n\n\n\nArdışık oy uzunluğuyla sonuç tahmini\n\n\n\n\n\n\nJun 10, 2023\n\n\nKaan Öztürk\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/tr/2023/secim-sandiginda-bayes/index.html",
    "href": "posts/tr/2023/secim-sandiginda-bayes/index.html",
    "title": "Seçim Sandığında Bayes",
    "section": "",
    "text": "28 Mayıs’daki cumhurbaşkanlığı seçiminde oyların sayılmasını izlerken bir şey dikkatimi çekti: Bulunduğum sandıkta Kemal Kılıçdaroğlu’na (KK) arka arkaya çok sayıda oy çıkarken, Recep Tayyip Erdoğan’a (RTE) ardışık olarak ikiden fazla oy çıkmıyordu. Yani bir veya iki oy RTE, ardından KK oyları, ardından bir veya iki RTE oyu, vs.\nBunun üzerine aklıma şu soru geldi: Sandıkta bir adayın nihai oy oranını, sayım sırasında o aday için gördüğümüz en uzun ardışık oy uzunluğuna dayanarak (oyların anlık sayısını görmediğimizi varsayarak) tahmin edebilir miyiz?\nBu anlamlı bir soru, çünkü o sandıkta adayın (bilinmeyen) oy oranı yüksekse, en uzun zincirin uzunluğu da ona göre artacaktır. Sıfıra yakın bir olasılıksa uzunluk biri aşmayacak, yüzde yüze yakınsa da sayılan oy sayısına yakın olacak.\nBu azami zincir uzunluğu kaç oyun sayıldığına da bağlı. Çok çok sayıda oy varsa, büyük sayılar yasası gereği düşük oy oranında bile herhangi bir uzunlukta zincir görmek mümkün. Tersten bakarsak, azami zincir uzunluğunu ikide sabitlemekle, oy sayısı arttıkça oy oranı tahminimiz sıfıra yaklaşmak zorunda kalacak. Sandıklarda sadece birkaç yüz oy olduğu için bu sınırlara yaklaşmayacağız tabii. Yine de bu aşırı durumları akılda tutmak sonuçlarımızı kontrol etmek için yararlı.\nSandıkta adayın oy oranına \\(r\\) diyelim. Bunu bilmiyoruz, kestirmek istiyoruz. Sandıkta toplam 352 oy var. Bunların tamamı açıldıktan sonra tahmin edecek bir şey kalmıyor. Belli bir sayıda, mesela 100 oy açıldıktan sonra sonucu tahmin etmek istiyoruz.\nİlk aşamada, 100 oy içinde adayın arka arkaya aldığı oy zincirlerinin en uzununun 2 olması olasılığını bulalım.\nBu olasılık belki analitik yoldan bulunabilir ama ben yapamadım, o yüzden rastgele sayı üreten kısa bir program yazdım:\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom itertools import groupby\n\ndef oylar_üret(r, oy_sayısı):\n    return random.choices((\"RTE\",\"KK\"), weights=[r, 1-r], k=oy_sayısı)\n\ndef en_uzun_dizi_uzunluğu(x, değer=\"RTE\"):\n    return max(len(list(y)) for c,y in groupby(x) if c==değer)\n    \ndef olabilirlik(r, oy_sayısı, deneme=1000, gözlenen_uzunluk=2):\n    sayaç = 0\n    for i in range(deneme):\n        oylar = oylar_üret(r, oy_sayısı)\n        try:\n            if en_uzun_dizi_uzunluğu(oylar) == gözlenen_uzunluk:\n                sayaç += 1\n        except ValueError: # birinci seçenek hiç gözlenmediyse\n            continue\n    return sayaç / deneme\nBirinci fonksiyon oylar_üret(r, oy_sayısı) iki adaylı bir seçimde, birinci adayın oy oranı r olacak şekilde oy_sayısı kadar rastgele oy üretir. İkinci fonksiyon ise, birincinin çıktısını alıp onun içinde ardışık değer zincirinin en büyük uzunluğunu bulur.\nÖrnek:\nrandom.seed(20232023)\ns = oylar_üret(r=0.2, oy_sayısı=10)\ns\n\n['KK', 'KK', 'KK', 'KK', 'KK', 'KK', 'KK', 'RTE', 'RTE', 'KK']\nen_uzun_dizi_uzunluğu(s, \"RTE\")\n\n2\nÜçüncü fonksiyon olabilirlik, en uzun dizi uzunluğunun tam 2 olduğu durumların olasılığını, aynı oy oranı ve oy sayısıyla birçok rastgele sandık üreterek kestirir.\nÖrneğin, oy oranı 0.2 ise ve 10 adet oy açıldıysa, tam 2 uzunlukta en az bir dizi olması olasılığı yaklaşık 0.22 olur.\nolabilirlik(0.2, oy_sayısı=10, deneme=10000, gözlenen_uzunluk=2)\n\n0.2184\nTabii biz asıl oy oranını bilmiyoruz, o yüzden tersten gideceğiz: Farklı oy oranları için, 100 oy içinde tam 2 uzunlukta en az bir dizi görme olabilirliğini hesaplayacağız.\nCode\nr = np.linspace(0, 1, 101)\nL = [olabilirlik(rr, oy_sayısı=100, deneme=100, gözlenen_uzunluk=2) for rr in r]\nplt.plot(r, L)\nplt.xlabel(\"RTE oy oranı\")\nplt.ylabel(\"Olabilirlik\")\nplt.grid()\n\n\n\n\n\nOy oranına göre, iki uzunlukta en az bir dizi görme olasılığı\nBu sandıkta, RTE’nin oy oranının olasılık dağılımının 0.5’e doğru neredeyse sıfıra indiğini görüyoruz. Dağılımın tepesi 0.15 değerinde. Dağılım geniş bir aralığa yayılmış olduğu için sonuç hakkında net bir şey söylemek şimdilik zor olsa da, yarıyı geçme şansının çok düşük olduğu anlaşılıyor."
  },
  {
    "objectID": "posts/tr/2023/secim-sandiginda-bayes/index.html#bayes-formülü",
    "href": "posts/tr/2023/secim-sandiginda-bayes/index.html#bayes-formülü",
    "title": "Seçim Sandığında Bayes",
    "section": "Bayes formülü",
    "text": "Bayes formülü\nBu noktada biraz duraklayıp bu problemi bir bayesçi kestirim alıştırması olarak ifade edelim. Oy oranı \\(r\\) ise ve \\(G\\) gözlemimizi (yani en uzun ardışık zincirin 2 uzunlukta olmasını) temsil ediyorsa, bu gözlem verilmiş olarak oy oranının olasılık dağılımını Bayes formülüyle ifade ederiz:\n\\[P(r | G) = \\frac{1}{P(G)}P(G|r)P(r)\\]\nÖnsel inanç: Burada \\(P(r)\\), bir şey gözlemeden önceki oy oranının dağılımıdır. Hiç bir şey gözlemediysek bunu nasıl bilebiliriz? Geçmiş tecrübelerimize dayanarak bir fikrimiz olabilir, veya her şey olabilir diyerek 0-1 arasında düzgün bir dağılım varsayabiliriz. Bu dağılıma önsel inanç (“prior belief”) denir.\nOlabilirlik: \\(P(G|r)\\) ifadesi, belli bir oy oranı \\(r\\) ile, gözlemimizin olasılığını verir. Yukarıdaki olabilirlik fonksiyonu tam bunu yapar. Bu faktörün teknik adı da zaten olabilirlik (“likelihood”).\nOlabilirlik fonksiyonu ile sonuçların nasıl üretildiğine dair modelimizi analizin içine katarız. Mesela burada, iki seçenekten birinin rastgele seçildiği bir Bernoulli modeli kullandık. Başka problemlerde başka modeller kullanılması gerekecektir.\nOlabilirlik, aslında aradığımız şeyin tersidir: Parametrelerin bilinen değeriyle çıktılar üretir. Oysa biz bu çıktılardan yola çıkarak parametrenin ne olduğuna dair bir fikir edinmek istiyoruz. Yukarıdaki Bayes formülü bu ters problemi çözmemizi sağlar.\nNormalleştirme: \\(P(G)\\) ifadesi bir normalleştirme sabitidir ve şu şekilde hesaplanabilir: \\[P(G) = \\sum_{r} P(G|r)P(r)\\] Ama genellikle bu sabiti doğrudan kullanmaya gerek olmaz.\nSonsal inanç: Yukarıdaki faktörleri birleştirerek elde ettiğimiz \\(P(r|G)\\) olasılığına sonsal inanç (“posterior belief”) denir. Bu, önsel inancımızın eldeki veriyle güncellenerek düzeltilmiş halidir."
  },
  {
    "objectID": "posts/tr/2023/secim-sandiginda-bayes/index.html#düzgün-önsel-ile-tahminler",
    "href": "posts/tr/2023/secim-sandiginda-bayes/index.html#düzgün-önsel-ile-tahminler",
    "title": "Seçim Sandığında Bayes",
    "section": "Düzgün önsel ile tahminler",
    "text": "Düzgün önsel ile tahminler\nŞimdi bunu problemimize uygulayalım. Düzgün dağılmış bir önsel alalım, yani RTE’nin bu sandıktaki oy oranının 0 ile 1 arasında eşit olasılıkla herhangi bir değerde olabileceğini düşünelim.\n\n\nCode\nr = np.linspace(0, 1, 101)\nprior = np.ones_like(r) \nprior /= sum(prior) # normalizasyon\n\n# her oy oranı için olabilirliği hesapla\nL = [olabilirlik(rr, oy_sayısı=100, deneme=100, gözlenen_uzunluk=2) for rr in r]\n\n# her oy oranı için sonsal olasılığı hesapla\nposterior = L*prior\nposterior /= sum(posterior) # normalizasyon\n\nplt.plot(r, prior, label=\"prior\")\nplt.plot(r, posterior, label=\"posterior\")\nplt.xlabel(\"RTE oy oranı\")\nplt.ylabel(\"Yoğunluk\")\nplt.title(\"$P(r|G)$, 100 oy\")\nplt.legend()\nplt.grid()\n\n\n\n\n\nÖnsel (prior) dağılım ve 100 oyda an az bir tane 2 uzunlukta zincir olabilirliği ile sonsal (posterior) dağılım\n\n\n\n\nÖnceki grafiğin aynısı çıktı, ki sabit bir önsel aldığımız için böyle olması gerek (olabilirliği sabit bir sayıyla çarpıyoruz)\nBurada tek bir oy oranı tahmini çıkarmıyoruz. Bayesçi kestirim bize tek tahminler değil, tahmin edilecek değişken için bir olasılık dağılımı verir. İsterseniz bu dağılımdan tek tahminler (point estimate) çıkarabilirsiniz. Örneğin en yüksek olasılıklı değeri 0.15, ortalama değeri 0.17 olarak bulabiliriz.\nBaşka bir özet sayı, sonsal dağılımın ortasında %90 alanı kaplayan aralığın (“highest posterior density interval”) sınırlarıdır. Buna göre RTE’nin oy oranını, %90 olasılıkla (0.06, 0.29) arasında tahmin edebiliriz.\n\n\nCode\nprint(f\"En muhtemel değer: { r[np.argmax(posterior)] : .2f}\")\nprint(f\"Ortalama değer: { np.sum(r*posterior): .2f}\")\nprint(f\"%90 yoğunluk aralığı: {r[(0.05&lt;np.cumsum(posterior))][0]}  - {r[(np.cumsum(posterior)&lt;0.95)][-1]}\")\n\n\nEn muhtemel değer:  0.14\nOrtalama değer:  0.17\n%90 yoğunluk aralığı: 0.06  - 0.29"
  },
  {
    "objectID": "posts/tr/2023/secim-sandiginda-bayes/index.html#güncelleme",
    "href": "posts/tr/2023/secim-sandiginda-bayes/index.html#güncelleme",
    "title": "Seçim Sandığında Bayes",
    "section": "Güncelleme",
    "text": "Güncelleme\nDiyelim 100 oy daha sayıldı ve RTE’ye yine en fazla 2 uzunlukta ardışık zincirler gözlediniz. Bu yeni veriyle RTE’nin oy oranına dair inancınızı (sonsal dağılımı) güncelleyebilirsiniz.\nBayesci analizin güzel tarafı, bunu yaparken sıfırdan başlamak zorunda olmamanız. Bir önceki adımda bulduğunuz sonsal dağılımı bu sefer önsel dağılım olarak kullanıp aynı işlemi tekrarlayabilirsiniz.\nOlabilirlik hesabını tekrarlamak zorunda değilsiniz, çünkü parametreler tamamen aynı olduğu için fonksiyon da aynı olacak.\n\n\nCode\nprior = posterior\n\n# her oy oranı için sonsal olasılığı hesapla\nposterior = L*prior\nposterior /= sum(posterior) # normalizasyon\n\nplt.plot(r, prior, label=\"prior\")\nplt.plot(r, posterior, label=\"posterior\")\nplt.xlabel(\"RTE oy oranı\")\nplt.ylabel(\"Yoğunluk\")\nplt.title(\"$P(r|G)$, 200 oy\")\nplt.legend()\nplt.grid()\n\nprint(f\"%90 yoğunluk aralığı: {r[(0.05&lt;np.cumsum(posterior))][0]}  - {r[(np.cumsum(posterior)&lt;0.95)][-1]}\")\n\n\n%90 yoğunluk aralığı: 0.07  - 0.24\n\n\n\n\n\nYeni veri ile tahmin güncelleme\n\n\n\n\nBu yeni veri ile sonsal dağılım biraz daha daraldı. Güncellemeden sonra %90 yoğunluk aralığı 0.08-0.24 oldu."
  },
  {
    "objectID": "posts/tr/2023/secim-sandiginda-bayes/index.html#farklı-olabilirlikler",
    "href": "posts/tr/2023/secim-sandiginda-bayes/index.html#farklı-olabilirlikler",
    "title": "Seçim Sandığında Bayes",
    "section": "Farklı olabilirlikler",
    "text": "Farklı olabilirlikler\nSandıktaki oyların sayımı bittiğinde RTE’nin 352 oydan 83’ünü aldığı görüldü. Yani gerçekleşen oran 0.24 olmuş. Bu değer yukarıda bulduğumuz %90 aralığının tam sınırında. Sonsal dağılımımız olması gerekenin biraz altında kalmış görünüyor.\nBunun birkaç sebebi olabilir. Birincisi, ardışık oy dizisi uzunluğu iyi bir gösterge olmayabilir. İkincisi, benim gözlemim yanlış olabilir. Belki başlarda arka arkaya üç tane RTE oyu çıkmıştır da, ben o sırada ardışıklığa dikkat etmediğim için kaçırmış olabilirim.\nHesabı bu ihtimale göre iki aşamada tekrarlayalım. İlk 100 oy içinde en uzun RTE zinciri 3 uzunlukta olsun, ondan sonraki 100 oy içinde 2 uzunlukta olsun.\n\n\nCode\nprior1 = np.ones_like(r)\nprior1 /= sum(prior1)\n\nL1 = [olabilirlik(rr, oy_sayısı=100, deneme=100, gözlenen_uzunluk=3) for rr in r]\nposterior1 = L1*prior1\nposterior1 /= sum(posterior1) # normalizasyon\n\nprior2 = posterior1\nL2 = [olabilirlik(rr, oy_sayısı=100, deneme=100, gözlenen_uzunluk=2) for rr in r]\nposterior2 = L2*prior2\nposterior2 /= sum(posterior2) # normalizasyon\n\nplt.plot(r, prior1, label=\"prior 1\")\nplt.plot(r, posterior1, label=\"posterior 1 (prior 2)\")\nplt.plot(r, posterior2, label=\"posterior 2\")\nplt.xlabel(\"RTE oy oranı\")\nplt.ylabel(\"Yoğunluk\")\nplt.title(\"$P(r|G)$\")\nplt.legend()\nplt.grid()\n\nprint(f\"%90 yoğunluk aralığı: {r[(0.05&lt;np.cumsum(posterior2))][0]}  - {r[(np.cumsum(posterior2)&lt;0.95)][-1]}\")\n\n\n%90 yoğunluk aralığı: 0.11  - 0.3\n\n\n\n\n\nİlk 100 oy içinde 3 uzunlukta en az bir zincir, ikinci 100 oy içinde 2 uzunlukta en az bir zincir gözlendiğinde sonsal dağılımlar\n\n\n\n\nİlk 100 oyda üçlü diziler olduğu için, birinci sonsal dağılımımız sağa kaymış, yani yüksek oy oranlarının olasılığı artmış. Bunun sonucu olarak da 200 oy gözlendikten sonraki sonsal, bir önceki çözümümüze göre daha sağa kaymış. Böylece %90 yoğunluk aralığı daha geniş ve gerçekleşen oranı içeriyor."
  },
  {
    "objectID": "posts/tr/2023/secim-sandiginda-bayes/index.html#farklı-önsel-geçmiş-seçimden-bilgi-aktarma",
    "href": "posts/tr/2023/secim-sandiginda-bayes/index.html#farklı-önsel-geçmiş-seçimden-bilgi-aktarma",
    "title": "Seçim Sandığında Bayes",
    "section": "Farklı önsel: Geçmiş seçimden bilgi aktarma",
    "text": "Farklı önsel: Geçmiş seçimden bilgi aktarma\nSon olarak, farklı bir önsel kullanmayı deneyelim.\nŞimdiye kadar kullandığımız önsel, bir aday için bütün oy oranlarının eşit olasılıkta olduğunu varsayıyordu. Oysa bunun doğru olmadığını geçmiş tecrübemizden biliyoruz. Seçimin birinci turunda aynı sandıkta 357 oyun 81’i RTE’ye gittiğini gözlemiştik. Bu bilgiyle, Beta dağılımına uyan bir önsel belirleyebiliriz:\n\\[P(r) = C\\ r^{81} (1-r)^{276}\\]\nYine, ilk 100 oyda en uzun zincirin 2 uzunlukta olduğunu varsayarak sonsal hesaplayalım.\n\n\nCode\nprior = r**81 * (1-r)**276\nprior /= sum(prior)\n\nL = [olabilirlik(rr, oy_sayısı=100, deneme=100, gözlenen_uzunluk=2) for rr in r]\nposterior = L*prior\nposterior /= sum(posterior)\n\nplt.plot(r, prior, label=\"prior\")\nplt.plot(r, posterior, label=\"posterior\")\nplt.xlabel(\"RTE oy oranı\")\nplt.ylabel(\"Yoğunluk\")\nplt.title(\"$P(r|G)$, 100 oy\")\nplt.legend()\nplt.xlim((0.1,0.4))\nplt.grid()\n\nprint(f\"%90 yoğunluk aralığı: {r[(0.05&lt;np.cumsum(posterior))][0]}  - {r[(np.cumsum(posterior)&lt;0.95)][-1]}\")\n\n\n%90 yoğunluk aralığı: 0.19  - 0.25\n\n\n\n\n\nGeçmiş seçimin oy oranlarıyla oluşturulan önsel ve bununla elde edilen sonsal dağılım.\n\n\n\n\n100 oy sayımında en fazla 2 uzunlukta zincir görmekle, sonsal olasılık dağılımının hafifçe sola kaydığını, yani oy oranının daha düşük ihtimallere kaydığını görüyoruz.\nAyrıca, daha belirli (informative) bir önsel seçmekle, sonsal dağılımımızın %90 yoğunluk aralığı daraldı, yani belirsizliği daha az bir sonuç elde ettik."
  },
  {
    "objectID": "posts/en/2023/combining-forecasts/index.html",
    "href": "posts/en/2023/combining-forecasts/index.html",
    "title": "Combining forecasts for better estimates",
    "section": "",
    "text": "In an earlier post, we discussed different methods for forecasting the future values of a variable. Forecasting is a rich subject: Even a cursory survey will suggest many different algorithms. Some algorithms, such as deep learning models, can be quite elaborate, and be able identify invisible patterns in the time series.\nHowever, sometimes even the best algorithm is not good enough.\nFor the rest of this post, we will assume that a set of forecasts is given. We don’t particularly care where they come from; they can be coming out of crystal balls for all we care. We will only discuss different ways to combine them, optionally adding some extra features."
  },
  {
    "objectID": "posts/en/2023/combining-forecasts/index.html#model-combination-methods",
    "href": "posts/en/2023/combining-forecasts/index.html#model-combination-methods",
    "title": "Combining forecasts for better estimates",
    "section": "Model combination methods",
    "text": "Model combination methods\n‍The Simple Mean method takes all forecasts for a particular target time and just averages them. No bells, no whistles. No parameters to estimate, no learning from the past. Still, it works surprisingly well. It frequently outperforms more sophisticated combinations.\nThe Simple Mean averages the forecasts with equal weight. However, if we have reason to trust some forecasters more than others, we can assign a greater weight to them so that they have a greater influence on the result. Usually, these weights are set using past data by evaluating the error of each forecaster. Forecasters with minor errors would carry greater weight in the result.\nOne such formula, the Minimum Variance method (also called the Inverse-Variance Weighting method), was proposed by Bates and Granger in 1969. It weights each forecaster according to its past precision, that is, the inverse of its variance. The variance of a forecaster can be estimated as the mean of the squares of its past errors.\nIt turns out that, when we average forecasts using the inverses of variances, the variance of the result is minimized; hence the name of the method. The same method is also used in portfolio theory to set up a stock portfolio that minimizes risk.\n‍Regression is the bread-and-butter of data scientists, and one might naturally use linear regression algorithms to determine the best parameters in the linear combination of forecasters.\nSo, how well do they work? Let us illustrate some of these methods on some example data: Hourly wind power production taken from two wind farms over more than two years."
  },
  {
    "objectID": "posts/en/2023/combining-forecasts/index.html#model-combination-on-wind-farm-production-forecast",
    "href": "posts/en/2023/combining-forecasts/index.html#model-combination-on-wind-farm-production-forecast",
    "title": "Combining forecasts for better estimates",
    "section": "Model combination on wind farm production forecast",
    "text": "Model combination on wind farm production forecast\nOur data is composed of three different sets of forecasts on two separate wind farms in Western Turkey, as well as the actual production on these farms. Two of the forecasters are commercial products based on meteorological models. The third is just a “persistence model”, which simply says that the production at the target time will be the same as the production two hours before it.\nHere is an overview of the commercial forecasts over one week, together with the actual production:  \nThe plots show that even though the forecasts follow the general trend, there are occasional dips and peaks in the production that the models do not capture. The addition of the persistence model would help us to capture such short-term variations.\nWe can assess the performance of the forecasts with mean absolute error over more than two years of data. Smaller values indicate a better forecaster:\n\n\n\nForecaster\nFarm 1\nFarm 2\n\n\n\n\nForecaster 1\n4.59\n3.78\n\n\nForecaster 2\n4.83\n4.60\n\n\nPersistence\n5.41\n3.74\n\n\n\nThe mean absolute error values have the same units (MW) as the production values. Farm 1 has a greater production capacity; accordingly, the errors there have larger values. We can compare forecast performances within each farm, but we should not compare one forecaster across farms.22 Alternatively, we can divide the mean-absolute value by the farm capacity. Then a comparison across farms is reasonable.\nWe see that on farm 1, the best performing model is Forecaster 1. The persistence model performs worst in Farm 1 but, interestingly, it is the best forecaster in Farm 2.\nNow, let us combine these models. The simplest combination is averaging the forecasts at each time step. The mean-absolute error of this combination is lower than any single forecaster:\n\n\n\nForecaster\nFarm 1\nFarm 2\n\n\n\n\nForecaster 1\n4.59\n3.78\n\n\nForecaster 2\n4.83\n4.60\n\n\nPersistence\n5.41\n3.74\n\n\nSimple Mean\n4.39\n3.59\n\n\n\nThis is impressive for such a simple step. Can we improve on this by using more sophisticated combinations, for example, by the Minimum Variance method?\nTo apply this, we need an additional step: We need to learn the weights we give to each forecaster. We split the two-year data set into training and test sets. Over the training set, we evaluate the mean square error of each forecaster, and use them as inverse weights. We then make predictions over the test set using this set of weights in the averaging. After that, the mean absolute errors are as follows:\n\n\n\nForecaster\nFarm 1\nFarm 2\n\n\n\n\nForecaster 1\n4.59\n3.78\n\n\nForecaster 2\n4.83\n4.60\n\n\nPersistence\n5.41\n3.74\n\n\nSimple Mean\n4.39\n3.59\n\n\nMinimum Variance\n4.38\n3.54\n\n\n\nWe see that the Minimum Variance method again outperforms the individual forecasts. However, it is not significantly better than Simple Mean, even though its algorithm is more complex.\nWe can try a cheat: Using our domain knowledge, we can enrich the data with some new features. For example, the wind follows the natural daily and yearly cycles, and the errors of individual forecasters may depend on the time of the day and year, instead of being constant all the time.\nTo try this hypothesis, we break the data into hours and months and evaluate each group’s mean square errors separately. This gives us a different weight for each (hour, month) pair. That way, the weights of forecaster 1 at 9:00 in January, 10:00 in January, and 9:00 in February will all be different.\nModifying our model combination algorithm this way, we get the following mean absolute error:\n\n\n\nForecaster\nFarm 1\nFarm 2\n\n\n\n\nForecaster 1\n4.59\n3.78\n\n\nForecaster 2\n4.83\n4.60\n\n\nPersistence\n5.41\n3.74\n\n\nSimple Mean\n4.39\n3.59\n\n\nMinimum Variance\n4.38\n3.54\n\n\nMinimum Variance, grouped by hour and month\n4.34\n3.53\n\n\n\nWe get an improved forecast as a result of grouping the data by month and hour. The improvement over the Simple Mean is slight. Still, depending on the objective, this can be significant.\nAs a last attempt, let us combine the three forecasts using linear regression. This model uses the month and hour information as categorical variables, in addition to the individual forecasts.\n\n\n\nForecaster\nFarm 1\nFarm 2\n\n\n\n\nForecaster 1\n4.59\n3.78\n\n\nForecaster 2\n4.83\n4.60\n\n\nPersistence\n5.41\n3.74\n\n\nSimple Mean\n4.39\n3.59\n\n\nMinimum Variance\n4.38\n3.54\n\n\nMinimum Variance, grouped by hour and month\n4.34\n3.53\n\n\nLinear Regression\n4.40\n3.51\n\n\n\nIn both farms, linear regression performs better than all individual forecasts. In Farm 2 it is the best one, albeit by a very small margin. However, in Farm 1, it performs slightly worse than other combined models.\nWe see that one combination method is not consistently better than others. On another farm, we might find that the Simple Mean is the most successful one. In practice, we would try out several combination methods in every farm, and pick the best one."
  },
  {
    "objectID": "posts/en/2023/combining-forecasts/index.html#what-else",
    "href": "posts/en/2023/combining-forecasts/index.html#what-else",
    "title": "Combining forecasts for better estimates",
    "section": "What else?",
    "text": "What else?\nWe can try other model combination algorithms as well. For example, Bayesian Model Averaging 3 is another method that assigns weights to the sum. It evaluates the Bayesian Information Criterion (BIC) for each forecaster using past data. Given the data, this parameter is related to the probability that this forecaster is the best one. These probabilities are used as the weights for the model combination.3 Hinne M, Gronau QF, van den Bergh D, Wagenmakers E-J. A Conceptual Introduction to Bayesian Model Averaging. Advances in Methods and Practices in Psychological Science. 2020;3(2):200-215.\nWe can assume that the weights are not constant but change over time. We can evaluate the weights only within a fixed time window, say, a few weeks before each target time. Then we can shift the window as we go along. Timmermann 4 lists several such methods.4 Timmermann, A. (2006). Forecast combinations, in Elliott G., Granger C. W. J. and Timmermann A. (eds), Handbook of Economic Forecasting, North-Holland, Amsterdam, pp. 135–196.\nHowever, going for more and more sophisticated combination algorithms may not always be useful. In many practical problems, it turns out that the Simple Mean is the best combination method (in the sense of minimum error). More complicated combination methods do not significantly reduce the error metric; they may even result in a bigger error. This observation is called the Forecast Combination Puzzle.\nThe main reason is that the weights of forecasters are not known beforehand, but are estimated from past data. This process itself introduces its own biases and errors. If the error variances of individual forecasters are close to each other, the weight estimation error will be dominant and throw us off course. To avoid this problem, Timmermann suggests using the Simple Mean, unless there is a reason to think that the error variance of forecasters is significantly different.\nThis brings us back to Occam’s Razor: Start simple, and improve only if necessary. Clever and sophisticated algorithms may look sexy, but simplest methods usually perform the best.\n(This post was first published in the Kavaken company blog on October 7, 2022.)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kaan Öztürk",
    "section": "",
    "text": "I am a senior data scientist, currently working at Kavaken, developing predictive analytics tools for wind turbines. I live in Istanbul and Tekirdağ with my family and our three cats.\nMy training is in physics, with a PhD in magnetospheric physics. I have taught in various universities for more than a decade, before leaving academia altogether for a career in data science.\nI’m a proud alumnus of İstanbul Erkek Lisesi, Boğaziçi University, and Rice University.\nThis site is mainly about my technical notes. For the interested, I have written a number of pieces in other websites (all in Turkish):\n\nYalansavar: Scientific skepticism\nAçık Bilim: Popular science\nVeri Defteri: Data science, machine learning, programming.\nBirGün Gazetesi: Biweekly column on scientific skepticism\nWordpress Blog: My other personal blog"
  }
]